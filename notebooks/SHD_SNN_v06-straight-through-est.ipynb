{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LSO() got an unexpected keyword argument 'variance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msnntorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spikeplot \u001b[38;5;28;01mas\u001b[39;00m splt\n\u001b[1;32m     22\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m spike_grad \u001b[38;5;241m=\u001b[39m \u001b[43msurrogate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m SAMPLE_T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m  \u001b[38;5;66;03m# Time steps per sample\u001b[39;00m\n\u001b[1;32m     29\u001b[0m SHD_TIMESTEP \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m  \u001b[38;5;66;03m# Time step of SHD dataset\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: LSO() got an unexpected keyword argument 'variance'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import snntorch\n",
    "import tonic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader\n",
    "from tonic import datasets, transforms\n",
    "from collections import namedtuple\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "spike_grad = surrogate.LSO(slope=0.13)\n",
    "\n",
    "\n",
    "\n",
    "SAMPLE_T = 128  # Time steps per sample\n",
    "SHD_TIMESTEP = 1e-6  # Time step of SHD dataset\n",
    "SHD_CHANNELS = 700  # Number of input channels in the SHD dataset\n",
    "NET_CHANNELS = 128  # Number of input channels in the network\n",
    "NET_DT = 1 / SAMPLE_T  # Time step for network\n",
    "BATCH_SIZE = 256  # Batch size\n",
    "NUM_EPOCHS = 100  # Increased number of epochs\n",
    "NUM_HIDDEN = 128  # Increased number of hidden units\n",
    "\n",
    "# Set the input and output shapes\n",
    "OBS_SHAPE = (NET_CHANNELS,)\n",
    "ACT_SHAPE = (20,)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up TensorBoard  \n",
    "run_name = f\"SNN_4_lif_hidden_{NUM_HIDDEN}_epochs_{NUM_EPOCHS}\"\n",
    "writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n",
    "\n",
    "class _SHD2Raster:\n",
    "    \"\"\"Helper for rasterizing SHD samples into frames.\"\"\"\n",
    "    def __init__(self, encoding_dim, sample_T=100):\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.sample_T = sample_T\n",
    "        \n",
    "    def __call__(self, events):\n",
    "        tensor = np.zeros((events[\"t\"].max() + 1, self.encoding_dim), dtype=int)\n",
    "        np.add.at(tensor, (events[\"t\"], events[\"x\"]), 1)\n",
    "        tensor = tensor[:self.sample_T, :]\n",
    "        tensor = np.minimum(tensor, 1)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Downsample(time_factor=SHD_TIMESTEP / NET_DT, spatial_factor=NET_CHANNELS / SHD_CHANNELS),\n",
    "    _SHD2Raster(NET_CHANNELS, sample_T=SAMPLE_T)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.SHD(\"../data\", train=True, transform=transform)\n",
    "test_dataset = datasets.SHD(\"../data\", train=False, transform=transform)\n",
    "\n",
    "\n",
    "def shuffle(dataset):\n",
    "    x, y = dataset\n",
    "    cutoff = y.shape[0] % BATCH_SIZE\n",
    "    indices = torch.randperm(y.shape[0])[:-cutoff]\n",
    "    x, y = x[indices], y[indices]\n",
    "    x = torch.reshape(x, (-1, BATCH_SIZE) + x.shape[1:])\n",
    "    y = torch.reshape(y, (-1, BATCH_SIZE))\n",
    "    return namedtuple(\"State\", \"obs labels\")(x, y)\n",
    "\n",
    "train_dl = iter(DataLoader(train_dataset, batch_size=len(train_dataset),\n",
    "                           collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=False))\n",
    "x_train, y_train = next(train_dl)\n",
    "x_train, y_train = x_train.to(torch.uint8), y_train.to(torch.uint8)\n",
    "x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "\n",
    "test_dl = iter(DataLoader(test_dataset, batch_size=len(test_dataset),\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=False))\n",
    "x_test, y_test = next(test_dl)\n",
    "x_test, y_test = x_test.to(torch.uint8), y_test.to(torch.uint8)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "x_test, y_test = shuffle((x_test, y_test))\n",
    "\n",
    "\n",
    "class SNNModel(torch.nn.Module):\n",
    "    def __init__(self, num_hidden=NUM_HIDDEN, output_size=20):\n",
    "        super(SNNModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(NET_CHANNELS, num_hidden)\n",
    "        self.lif1 = snntorch.Leaky(beta=torch.ones(num_hidden) * 0.5, learn_beta=True, spike_grad=spike_grad)\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = snntorch.Leaky(beta=torch.ones(num_hidden) * 0.5, learn_beta=True, spike_grad=spike_grad)\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif3 = snntorch.Leaky(beta=torch.ones(num_hidden) * 0.5, learn_beta=True, spike_grad=spike_grad)\n",
    "        \n",
    "        self.fc4 = torch.nn.Linear(num_hidden, output_size)\n",
    "        self.lif4 = snntorch.Leaky(beta=torch.ones(output_size) * 0.5, learn_beta=True, reset_mechanism=\"none\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        mem1, mem2, mem3, mem4 = self.lif1.init_leaky(), self.lif2.init_leaky(), self.lif3.init_leaky(), self.lif4.init_leaky()\n",
    "        spikes = []\n",
    "\n",
    "        for step in x:\n",
    "            cur1 = self.fc1(step)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            cur4 = self.fc4(spk3)\n",
    "            spk4, mem4 = self.lif4(cur4, mem4)\n",
    "            spikes.append(mem4)\n",
    "\n",
    "        return torch.stack(spikes, axis=0).permute(1, 0, 2)\n",
    "\n",
    "model = SNNModel(num_hidden=NUM_HIDDEN).to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    return (torch.argmax(predictions, axis=-1) == targets).sum().item() / len(targets)\n",
    "\n",
    "# train loop and logging\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_batch = shuffle((x_train, y_train))\n",
    "    train_data, targets = train_batch\n",
    "\n",
    "    for data, target in zip(train_data, targets):\n",
    "        optimizer.zero_grad()\n",
    "        out_V = model(data)\n",
    "        loss_val = loss_fn(torch.sum(out_V, axis=-2), target)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    train_acc = accuracy(torch.sum(out_V, axis=-2), target)\n",
    "    writer.add_scalar(\"Loss/train\", loss_val.item(), epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss_val.item()} | Training Accuracy: {train_acc}\")\n",
    "\n",
    "# Evaluation and Confusion Matrix\n",
    "def evaluate(model, x_test, y_test):\n",
    "    model.eval()\n",
    "    test_acc = []\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for test_data, test_targets in zip(x_test, y_test):\n",
    "            out_V = model(test_data)\n",
    "            test_acc.append(accuracy(torch.sum(out_V, axis=-2), test_targets))\n",
    "            all_preds.append(torch.argmax(torch.sum(out_V, axis=-2), axis=-1))\n",
    "            all_targets.append(test_targets)\n",
    "\n",
    "    avg_test_acc = np.mean(test_acc)\n",
    "    all_preds, all_targets = torch.cat(all_preds), torch.cat(all_targets)\n",
    "    cm = confusion_matrix(all_targets.cpu(), all_preds.cpu())\n",
    "    cm_display = ConfusionMatrixDisplay(cm, display_labels=[str(i) for i in range(20)])\n",
    "    \n",
    "    return avg_test_acc, cm_display\n",
    "\n",
    "# visualise results\n",
    "test_acc, cm_display = evaluate(model, x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "cm_display.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
